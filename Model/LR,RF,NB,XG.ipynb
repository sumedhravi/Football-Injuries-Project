{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.ensemble import GradientBoostingClassifier as XgBoost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,f1_score\n",
    "from sklearn.metrics import average_precision_score as auc\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.utils import resample as resample\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from joblib import dump, load\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Centre-Back</th>\n",
       "      <th>Right Winger</th>\n",
       "      <th>Left Winger</th>\n",
       "      <th>Goalkeeper</th>\n",
       "      <th>Central Midfield</th>\n",
       "      <th>Right-Back</th>\n",
       "      <th>Left-Back</th>\n",
       "      <th>...</th>\n",
       "      <th>head_days</th>\n",
       "      <th>minor_</th>\n",
       "      <th>minor_days</th>\n",
       "      <th>foot</th>\n",
       "      <th>lower_leg</th>\n",
       "      <th>upper_leg</th>\n",
       "      <th>upper_body</th>\n",
       "      <th>arms</th>\n",
       "      <th>head</th>\n",
       "      <th>minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>193</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>175</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>175</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>193</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>182</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>16.0</td>\n",
       "      <td>195</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>17.0</td>\n",
       "      <td>173</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>29.0</td>\n",
       "      <td>182</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>18.0</td>\n",
       "      <td>178</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>28.0</td>\n",
       "      <td>194</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Height  Weight  Centre-Back  Right Winger  Left Winger  \\\n",
       "0     30.0     193      87            1             0            0   \n",
       "1     29.0     175      71            0             1            0   \n",
       "2     29.0     175      69            0             0            1   \n",
       "3     29.0     193      91            0             0            0   \n",
       "4     31.0     182      67            0             0            0   \n",
       "...    ...     ...     ...          ...           ...          ...   \n",
       "1272  16.0     195      96            1             0            0   \n",
       "1273  17.0     173      61            0             0            0   \n",
       "1274  29.0     182      75            0             0            0   \n",
       "1275  18.0     178      68            0             0            0   \n",
       "1276  28.0     194      90            0             0            0   \n",
       "\n",
       "      Goalkeeper  Central Midfield  Right-Back  Left-Back  ...  head_days  \\\n",
       "0              0                 0           0          0  ...        0.0   \n",
       "1              0                 0           0          0  ...        0.0   \n",
       "2              0                 0           0          0  ...        0.0   \n",
       "3              1                 0           0          0  ...        0.0   \n",
       "4              0                 1           0          0  ...        0.0   \n",
       "...          ...               ...         ...        ...  ...        ...   \n",
       "1272           0                 0           0          0  ...        0.0   \n",
       "1273           0                 0           0          0  ...        0.0   \n",
       "1274           0                 0           0          1  ...       17.0   \n",
       "1275           0                 0           0          0  ...        0.0   \n",
       "1276           1                 0           0          0  ...        0.0   \n",
       "\n",
       "      minor_  minor_days  foot  lower_leg  upper_leg  upper_body  arms  head  \\\n",
       "0          0         0.0     0          0          0           0     0     0   \n",
       "1          3        99.0     0          0          0           0     0     0   \n",
       "2          4       114.0     1          0          1           1     0     0   \n",
       "3          0         0.0     0          0          0           0     0     0   \n",
       "4          0         0.0     1          0          0           0     0     0   \n",
       "...      ...         ...   ...        ...        ...         ...   ...   ...   \n",
       "1272       0         0.0     0          0          0           0     0     0   \n",
       "1273       0         0.0     0          0          0           0     0     0   \n",
       "1274       2        25.0     0          0          1           1     0     0   \n",
       "1275       0         0.0     0          0          0           1     0     0   \n",
       "1276       0         0.0     0          0          1           0     0     0   \n",
       "\n",
       "      minor  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  \n",
       "...     ...  \n",
       "1272      0  \n",
       "1273      1  \n",
       "1274      1  \n",
       "1275      1  \n",
       "1276      0  \n",
       "\n",
       "[1277 rows x 37 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_foot = data['foot']\n",
    "y_data_lower_leg = data['lower_leg']\n",
    "y_data_upper_leg = data['upper_leg']\n",
    "y_data_upper_body = data['upper_body']\n",
    "y_data_arms = data['arms']\n",
    "y_data_head = data['head']\n",
    "y_data_minor = data['minor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10806577916992952"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_data_foot)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08144087705559906"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_data_lower_leg)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1331245105716523"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_data_upper_leg)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11041503523884104"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_data_upper_body)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14095536413469067"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_data_arms)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014095536413469069"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_data_head)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['foot', 'lower_leg', 'upper_leg', 'upper_body', 'arms', 'head', 'minor']\n",
    "x_data = data.drop(y_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1277, 30)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(x,y):\n",
    "    \n",
    "    X_oversampled, y_oversampled = resample(x[y == 1],\n",
    "                                            y[y == 1],\n",
    "                                            replace=True,\n",
    "                                            n_samples=int(x[y == 0].shape[0]*.7))\n",
    "\n",
    "    x = np.vstack((x, X_oversampled))\n",
    "    y = np.hstack((y, y_oversampled))\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ind=np.random.choice(len(data),round(len(data)*.4),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=614)\n",
    "x_train,y_train=resample_data(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 688, 1: 559})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_NB1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=614)\n",
    "    #x_train,y_train=resample_data(x_train,y_train)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    nb=NB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=50)}\n",
    "    NB_foot = GridSearchCV(estimator=nb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc, recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    dump(NB_foot,'Foot_NB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_NB_resam():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=614)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "\n",
    "    nb=NB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=50)}\n",
    "    NB_foot = GridSearchCV(estimator=nb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc, recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    \n",
    "    nb=NB().fit(x_train,y_train)\n",
    "    \n",
    "    foot_predictions = nb.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc, recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_NB():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=614)\n",
    "    #x_train,y_train=resample_data(x_train,y_train)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    nb=NB().fit(x_train,y_train)\n",
    "    \n",
    "    foot_predictions = nb.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc, recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5322896281800391 0.1554770318021201 0.1105373852962771 0.36666666666666664 0.09865470852017937\n"
     ]
    }
   ],
   "source": [
    "foot_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6320939334637965 0.13761467889908258 0.11179679952438752 0.25 0.0949367088607595\n",
      "{'var_smoothing': 3.727593720314938e-07}\n"
     ]
    }
   ],
   "source": [
    "foot_NB1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5733855185909981 0.2043795620437956 0.12368149922880431 0.4666666666666667 0.1308411214953271\n",
      "{'var_smoothing': 4.71486636345739e-06}\n",
      "0.3424657534246575 0.19617224880382778 0.11544084152372207 0.6833333333333333 0.11452513966480447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "foot_NB_resam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_XG1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=614)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    xg = XgBoost()\n",
    "    params_XG= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'max_features': ['auto','sqrt','log2']}\n",
    "    NB_foot=RandomizedSearchCV(xg,params_XG, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    dump(NB_foot,'xg_foot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_XG():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=614)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    xg = XgBoost().fit(x_train, y_train)\n",
    "    foot_predictions = xg.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    dump(xg,\"Foot_XG.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_XG_resam():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=614)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    xg = XgBoost()\n",
    "    params_XG= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'max_features': ['auto','sqrt','log2']}\n",
    "    NB_foot=RandomizedSearchCV(xg,params_XG, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    dump(NB_foot,'xg_foot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8590998043052838 0.14285714285714288 0.13067514677103717 0.1 0.25\n"
     ]
    }
   ],
   "source": [
    "foot_XG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8551859099804305 0.05128205128205128 0.11720663912444734 0.03333333333333333 0.1111111111111111\n",
      "{'n_estimators': 100, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "foot_XG1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_LR1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000)\n",
    "    params_lr= {\n",
    "    'C':np.logspace(-3,3,num=50)}\n",
    "    NB_foot=RandomizedSearchCV(lr,params_lr, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    dump(NB_foot,'lr_foot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_LR():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000).fit(x_train,y_train)\n",
    "\n",
    "    foot_predictions = lr.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8669275929549902 0.05555555555555555 0.1058764787836325 0.037037037037037035 0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "foot_LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747553816046967 0.058823529411764705 0.10705225773718924 0.037037037037037035 0.14285714285714285\n",
      "{'C': 104.81131341546853}\n"
     ]
    }
   ],
   "source": [
    "foot_LR1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foot_RF():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_foot, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    NB_foot=RandomForestClassifier().fit(x_train,y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8786692759295499 0.06060606060606061 0.10793409195235679 0.037037037037037035 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "foot_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_leg_NB1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_lower_leg, test_size=0.4, random_state=12)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=50)}\n",
    "    NB_lower_leg = GridSearchCV(estimator=nb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    lower_leg_predictions = NB_lower_leg.predict(x_test)\n",
    "    lower_leg_score = accuracy_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_f1_score = f1_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_auc = auc(y_test, lower_leg_predictions)\n",
    "    print(lower_leg_score, lower_leg_f1_score, lower_leg_auc,recall(y_test,lower_leg_predictions),precision(y_test,lower_leg_predictions))\n",
    "    print(NB_lower_leg.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_leg_NB():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_lower_leg, test_size=0.4, random_state=12)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB().fit(x_train, y_train)\n",
    "    lower_leg_predictions = nb.predict(x_test)\n",
    "    lower_leg_score = accuracy_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_f1_score = f1_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_auc = auc(y_test, lower_leg_predictions)\n",
    "    print(lower_leg_score, lower_leg_f1_score, lower_leg_auc,recall(y_test,lower_leg_predictions),precision(y_test,lower_leg_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22700587084148727 0.1280353200883002 0.07416004431302901 0.6904761904761905 0.0705596107055961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "lower_leg_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8434442270058709 0.13043478260869565 0.08759295499021526 0.14285714285714285 0.12\n",
      "{'var_smoothing': 0.4291934260128778}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "lower_leg_NB1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_leg_XG1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_lower_leg, test_size=0.4, random_state=12)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost()\n",
    "    params_XG= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'max_features': ['auto','sqrt','log2']}\n",
    "    NB_lower_leg=RandomizedSearchCV(xg,params_XG, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    lower_leg_predictions = NB_lower_leg.predict(x_test)\n",
    "    lower_leg_score = accuracy_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_f1_score = f1_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_auc = auc(y_test, lower_leg_predictions)\n",
    "    print(lower_leg_score, lower_leg_f1_score, lower_leg_auc,recall(y_test,lower_leg_predictions),precision(y_test,lower_leg_predictions))\n",
    "    print(NB_lower_leg.best_params_)\n",
    "    dump(NB_lower_leg,'Lleg_XG.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_leg_XG():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_lower_leg, test_size=0.4, random_state=12)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost().fit(x_train, y_train)\n",
    "    lower_leg_predictions = xg.predict(x_test)\n",
    "    lower_leg_score = accuracy_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_f1_score = f1_score(y_test, lower_leg_predictions)\n",
    "    lower_leg_auc = auc(y_test, lower_leg_predictions)\n",
    "    print(lower_leg_score, lower_leg_f1_score, lower_leg_auc,recall(y_test,lower_leg_predictions),precision(y_test,lower_leg_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8101761252446184 0.1415929203539823 0.0879983094916531 0.19047619047619047 0.11267605633802817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "lower_leg_XG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9099804305283757 0.0 0.0821917808219178 0.0 0.0\n",
      "{'n_estimators': 150, 'max_features': 'log2', 'max_depth': 9, 'learning_rate': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "lower_leg_XG1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_leg_LR1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_lower_leg, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000)\n",
    "    params_lr= {\n",
    "    'C':np.logspace(-3,3,num=50)}\n",
    "    NB_foot=RandomizedSearchCV(lr,params_lr, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    dump(NB_foot,'lr_foot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_leg_LR():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_lower_leg, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000).fit(x_train, y_train)\n",
    "    foot_predictions = lr.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8845401174168297 0.06349206349206349 0.08281303388935482 0.047619047619047616 0.09523809523809523\n"
     ]
    }
   ],
   "source": [
    "lower_leg_LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8884540117416829 0.033898305084745756 0.08163539388358082 0.023809523809523808 0.058823529411764705\n",
      "{'C': 184.20699693267164}\n"
     ]
    }
   ],
   "source": [
    "lower_leg_LR1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_leg_RF():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_lower_leg, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    NB_foot=RandomForestClassifier().fit(x_train,y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    dump(NB_foot,\"Lleg_RF.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8962818003913894 0.10169491525423728 0.08892598135144468 0.07142857142857142 0.17647058823529413\n"
     ]
    }
   ],
   "source": [
    "lower_leg_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_leg_NB1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_leg, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=50)}\n",
    "    NB_upper_leg = GridSearchCV(estimator=nb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    upper_leg_predictions = NB_upper_leg.predict(x_test)\n",
    "    upper_leg_score = accuracy_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_f1_score = f1_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_auc = auc(y_test, upper_leg_predictions)\n",
    "    print(upper_leg_score, upper_leg_f1_score, upper_leg_auc,recall(y_test,upper_leg_predictions),precision(y_test,upper_leg_predictions))\n",
    "    print(NB_upper_leg.best_params_)\n",
    "    dump(NB_upper_leg,\"Uleg_NB.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_leg_NB():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_leg, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB().fit(x_train, y_train)\n",
    "    upper_leg_predictions = nb.predict(x_test)\n",
    "    upper_leg_score = accuracy_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_f1_score = f1_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_auc = auc(y_test, upper_leg_predictions)\n",
    "    print(upper_leg_score, upper_leg_f1_score, upper_leg_auc,recall(y_test,upper_leg_predictions),precision(y_test,upper_leg_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6105675146771037 0.2656826568265683 0.15449555456237715 0.5454545454545454 0.17560975609756097\n",
      "{'var_smoothing': 5.4286754393238595e-09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_leg_NB1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.589041095890411 0.27586206896551724 0.1591057344482002 0.6060606060606061 0.17857142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_leg_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_leg_XG1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_leg, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost()\n",
    "    params_XG= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'max_features': ['auto','sqrt','log2']}\n",
    "    NB_upper_leg=RandomizedSearchCV(xg,params_XG, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    upper_leg_predictions = NB_upper_leg.predict(x_test)\n",
    "    upper_leg_score = accuracy_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_f1_score = f1_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_auc = auc(y_test, upper_leg_predictions)\n",
    "    print(upper_leg_score, upper_leg_f1_score, upper_leg_auc,recall(y_test,upper_leg_predictions),precision(y_test,upper_leg_predictions))\n",
    "    print(NB_upper_leg.best_params_)\n",
    "    dump(NB_upper_leg,'xg_uleg.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_leg_XG():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_leg, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost().fit(x_train, y_train)\n",
    "    upper_leg_predictions = xg.predict(x_test)\n",
    "    upper_leg_score = accuracy_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_f1_score = f1_score(y_test, upper_leg_predictions)\n",
    "    upper_leg_auc = auc(y_test, upper_leg_predictions)\n",
    "    print(upper_leg_score, upper_leg_f1_score, upper_leg_auc,recall(y_test,upper_leg_predictions),precision(y_test,upper_leg_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7671232876712328 0.2515723270440252 0.15518737657491524 0.30303030303030304 0.21505376344086022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_leg_XG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8669275929549902 0.028571428571428574 0.13098944434560872 0.015151515151515152 0.25\n",
      "{'n_estimators': 150, 'max_features': 'sqrt', 'max_depth': 8, 'learning_rate': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_leg_XG1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_leg_LR1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_leg, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000)\n",
    "    params_lr= {\n",
    "    'C':np.logspace(-3,3,num=50)}\n",
    "    NB_foot=RandomizedSearchCV(lr,params_lr, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    dump(NB_foot,'lr_foot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_leg_LR():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_leg, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000).fit(x_train, y_train)\n",
    "    foot_predictions = lr.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8180039138943248 0.1308411214953271 0.14441519742503728 0.09859154929577464 0.19444444444444445\n"
     ]
    }
   ],
   "source": [
    "upper_leg_LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8277886497064579 0.12000000000000001 0.14468578119638947 0.08450704225352113 0.20689655172413793\n",
      "{'C': 244.205309454865}\n"
     ]
    }
   ],
   "source": [
    "upper_leg_LR1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_leg_RF():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_leg, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    NB_foot=RandomForestClassifier().fit(x_train,y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    dump(NB_foot,\"Uleg_RF.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8277886497064579 0.18518518518518517 0.1574400121573573 0.14084507042253522 0.2702702702702703\n"
     ]
    }
   ],
   "source": [
    "upper_leg_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_NB1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_body, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=50)}\n",
    "    NB_upper_body = GridSearchCV(estimator=nb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    upper_body_predictions = NB_upper_body.predict(x_test)\n",
    "    upper_body_score = accuracy_score(y_test, upper_body_predictions)\n",
    "    upper_body_f1_score = f1_score(y_test, upper_body_predictions)\n",
    "    upper_body_auc = auc(y_test, upper_body_predictions)\n",
    "    print(upper_body_score, upper_body_f1_score, upper_body_auc,recall(y_test,upper_body_predictions),precision(y_test,upper_body_predictions))\n",
    "    print(NB_upper_body.best_params_)\n",
    "    dump(NB_upper_body,'Ubody_NB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_NB():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_body, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB().fit(x_train, y_train)\n",
    "    upper_body_predictions = nb.predict(x_test)\n",
    "    upper_body_score = accuracy_score(y_test, upper_body_predictions)\n",
    "    upper_body_f1_score = f1_score(y_test, upper_body_predictions)\n",
    "    upper_body_auc = auc(y_test, upper_body_predictions)\n",
    "    print(upper_body_score, upper_body_f1_score, upper_body_auc,recall(y_test,upper_body_predictions),precision(y_test,upper_body_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37377690802348335 0.23444976076555024 0.13533054924430882 0.765625 0.1384180790960452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_body_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5812133072407045 0.21897810218978103 0.1335004892367906 0.46875 0.14285714285714285\n",
      "{'var_smoothing': 0.00013894954943731373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_body_NB1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_XG1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_body, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost()\n",
    "    params_XG= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'max_features': ['auto','sqrt','log2']}\n",
    "    NB_upper_body=RandomizedSearchCV(xg,params_XG, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    upper_body_predictions = NB_upper_body.predict(x_test)\n",
    "    upper_body_score = accuracy_score(y_test, upper_body_predictions)\n",
    "    upper_body_f1_score = f1_score(y_test, upper_body_predictions)\n",
    "    upper_body_auc = auc(y_test, upper_body_predictions)\n",
    "    print(upper_body_score, upper_body_f1_score, upper_body_auc,recall(y_test,upper_body_predictions),precision(y_test,upper_body_predictions))\n",
    "    print(NB_upper_body.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_XG():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_body, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost().fit(x_train, y_train)\n",
    "    upper_body_predictions = xg.predict(x_test)\n",
    "    upper_body_score = accuracy_score(y_test, upper_body_predictions)\n",
    "    upper_body_f1_score = f1_score(y_test, upper_body_predictions)\n",
    "    upper_body_auc = auc(y_test, upper_body_predictions)\n",
    "    print(upper_body_score, upper_body_f1_score, upper_body_auc,recall(y_test,upper_body_predictions),precision(y_test,upper_body_predictions))\n",
    "    dump(xg,\"Ubody_XG.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7729941291585127 0.15942028985507245 0.12926718609509705 0.171875 0.14864864864864866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_body_XG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8688845401174168 0.028985507246376812 0.1264126712328767 0.015625 0.2\n",
      "{'n_estimators': 50, 'max_features': 'log2', 'max_depth': 9, 'learning_rate': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "upper_body_XG1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_LR():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_body, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000).fit(x_train, y_train)\n",
    "    foot_predictions = lr.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_LR1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_body, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000)\n",
    "    params_lr= {\n",
    "    'C':np.logspace(-3,3,num=50)}\n",
    "    NB_foot=RandomizedSearchCV(lr,params_lr, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_RF():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_upper_body, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    NB_foot=RandomForestClassifier().fit(x_train,y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863013698630137 0.07894736842105263 0.10099228732588926 0.058823529411764705 0.12\n"
     ]
    }
   ],
   "source": [
    "upper_body_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8551859099804305 0.0975609756097561 0.10209669373715018 0.0784313725490196 0.12903225806451613\n"
     ]
    }
   ],
   "source": [
    "upper_body_LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8590998043052838 0.1 0.10279463698563979 0.0784313725490196 0.13793103448275862\n",
      "{'C': 138.9495494373136}\n"
     ]
    }
   ],
   "source": [
    "upper_body_LR1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arms_NB():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_arms, test_size=0.4, random_state=1)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB().fit(x_train, y_train)\n",
    "    arms_predictions = nb.predict(x_test)\n",
    "    arms_score = accuracy_score(y_test, arms_predictions)\n",
    "    arms_f1_score = f1_score(y_test, arms_predictions)\n",
    "    arms_auc = auc(y_test, arms_predictions)\n",
    "    print(arms_score, arms_f1_score, arms_auc,recall(y_test,arms_predictions),precision(y_test,arms_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arms_NB1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_arms, test_size=0.4, random_state=1)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=50)}\n",
    "    NB_arms = GridSearchCV(estimator=nb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    arms_predictions = NB_arms.predict(x_test)\n",
    "    arms_score = accuracy_score(y_test, arms_predictions)\n",
    "    arms_f1_score = f1_score(y_test, arms_predictions)\n",
    "    arms_auc = auc(y_test, arms_predictions)\n",
    "    print(arms_score, arms_f1_score, arms_auc,recall(y_test,arms_predictions),precision(y_test,arms_predictions))\n",
    "    print(NB_arms.best_params_)\n",
    "    dump(NB_arms,'nb_arms.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.324853228962818 0.24836601307189543 0.14661387303164575 0.7808219178082192 0.14766839378238342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "arms_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6086105675146771 0.23076923076923078 0.1500779639377544 0.410958904109589 0.16042780748663102\n",
      "{'var_smoothing': 2.4420530945486497e-07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "arms_NB1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arms_XG1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_arms, test_size=0.4, random_state=1)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost()\n",
    "    params_XG= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'max_features': ['auto','sqrt','log2']}\n",
    "    NB_arms=RandomizedSearchCV(xg,params_XG, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    arms_predictions = NB_arms.predict(x_test)\n",
    "    arms_score = accuracy_score(y_test, arms_predictions)\n",
    "    arms_f1_score = f1_score(y_test, arms_predictions)\n",
    "    arms_auc = auc(y_test, arms_predictions)\n",
    "    print(arms_score, arms_f1_score, arms_auc,recall(y_test,arms_predictions),precision(y_test,arms_predictions))\n",
    "    print(NB_arms.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arms_XG():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_arms, test_size=0.4, random_state=1)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost().fit(x_train, y_train)\n",
    "    arms_predictions = xg.predict(x_test)\n",
    "    arms_score = accuracy_score(y_test, arms_predictions)\n",
    "    arms_f1_score = f1_score(y_test, arms_predictions)\n",
    "    arms_auc = auc(y_test, arms_predictions)\n",
    "    print(arms_score, arms_f1_score, arms_auc,recall(y_test,arms_predictions),precision(y_test,arms_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7299412915851272 0.15853658536585366 0.14285714285714285 0.1780821917808219 0.14285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "arms_XG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8258317025440313 0.0 0.14285714285714285 0.0 0.0\n",
      "{'n_estimators': 150, 'max_features': 'log2', 'max_depth': 7, 'learning_rate': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "arms_XG1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arms_LR1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_arms, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000)\n",
    "    params_lr= {\n",
    "    'C':np.logspace(-3,3,num=50)}\n",
    "    NB_foot=RandomizedSearchCV(lr,params_lr, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "    dump(NB_foot,\"Arm_LR.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arms_LR():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_arms, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000).fit(x_train, y_train)\n",
    "    foot_predictions = lr.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arms_RF():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_arms, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    NB_foot=RandomForestClassifier().fit(x_train,y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    dump(NB_foot,\"Arm_RF.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160469667318982 0.06 0.1606963868073123 0.036585365853658534 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "arms_LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821917808219178 0.09900990099009901 0.16673114460055918 0.06097560975609756 0.2631578947368421\n",
      "{'C': 323.745754281764}\n"
     ]
    }
   ],
   "source": [
    "arms_LR1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160469667318982 0.11320754716981131 0.16702066727125195 0.07317073170731707 0.25\n"
     ]
    }
   ],
   "source": [
    "arms_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_NB():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_head, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB().fit(x_train, y_train)\n",
    "    head_predictions = nb.predict(x_test)\n",
    "    head_score = accuracy_score(y_test, head_predictions)\n",
    "    head_f1_score = f1_score(y_test, head_predictions)\n",
    "    head_auc = auc(y_test, head_predictions)\n",
    "    print(head_score, head_f1_score, head_auc,recall(y_test,head_predictions),precision(y_test,head_predictions))\n",
    "    dump(nb,\"Head_NB.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_NB1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_head, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    nb=NB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=50)}\n",
    "    NB_head = GridSearchCV(estimator=nb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=5,   \n",
    "                  n_jobs=-1).fit(x_train, y_train)\n",
    "    head_predictions = NB_head.predict(x_test)\n",
    "    head_score = accuracy_score(y_test, head_predictions)\n",
    "    head_f1_score = f1_score(y_test, head_predictions)\n",
    "    head_auc = auc(y_test, head_predictions)\n",
    "    print(head_score, head_f1_score, head_auc,recall(y_test,head_predictions),precision(y_test,head_predictions))\n",
    "    print(NB_head.best_params_)\n",
    "    dump(NB_head,'nb_head.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6477495107632094 0.04255319148936171 0.019716455241059205 0.4444444444444444 0.0223463687150838\n",
      "{'var_smoothing': 4.71486636345739e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "head_NB1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49706457925636005 0.0446096654275093 0.02125545687189523 0.6666666666666666 0.023076923076923078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "head_NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_XG():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_head, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost().fit(x_train, y_train)\n",
    "    head_predictions = xg.predict(x_test)\n",
    "    head_score = accuracy_score(y_test, head_predictions)\n",
    "    head_f1_score = f1_score(y_test, head_predictions)\n",
    "    head_auc = auc(y_test, head_predictions)\n",
    "    print(head_score, head_f1_score, head_auc,recall(y_test,head_predictions),precision(y_test,head_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_XG1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_head, test_size=0.4, random_state=500)\n",
    "    x_train,y_train=resample_data(x_train,y_train)\n",
    "    xg = XgBoost()\n",
    "    params_XG= {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': range(3, 10),\n",
    "    'max_features': ['auto','sqrt','log2']}\n",
    "    NB_head=RandomizedSearchCV(xg,params_XG, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    head_predictions = NB_head.predict(x_test)\n",
    "    head_score = accuracy_score(y_test, head_predictions)\n",
    "    head_f1_score = f1_score(y_test, head_predictions)\n",
    "    head_auc = auc(y_test, head_predictions)\n",
    "    print(head_score, head_f1_score, head_auc,recall(y_test,head_predictions),precision(y_test,head_predictions))\n",
    "    print(NB_head.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9726027397260274 0.0 0.01761252446183953 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "head_XG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9823874755381604 0.0 0.01761252446183953 0.0 0.0\n",
      "{'n_estimators': 50, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "head_XG1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_LR1():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_head, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000)\n",
    "    params_lr= {\n",
    "    'C':np.logspace(-3,3,num=50)}\n",
    "    NB_foot=RandomizedSearchCV(lr,params_lr, \n",
    "                 cv=5,   \n",
    "                 n_jobs=-1).fit(x_train, y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "    print(NB_foot.best_params_)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_LR():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_head, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    lr=LogisticRegression(max_iter=10000).fit(x_train, y_train)\n",
    "    foot_predictions = lr.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_RF():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data_head, test_size=0.4, random_state=0)\n",
    "    smt = SMOTE(random_state=0)\n",
    "    x_train, y_train = smt.fit_resample(x_train, y_train)\n",
    "    NB_foot=RandomForestClassifier().fit(x_train,y_train)\n",
    "    foot_predictions = NB_foot.predict(x_test)\n",
    "    foot_score = accuracy_score(y_test, foot_predictions)\n",
    "    foot_f1_score = f1_score(y_test, foot_predictions)\n",
    "    foot_auc = auc(y_test, foot_predictions)\n",
    "    print(foot_score, foot_f1_score, foot_auc,recall(y_test,foot_predictions),precision(y_test,foot_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9647749510763209 0.0 0.019569471624266144 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "head_LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974559686888454 0.0 0.019569471624266144 0.0 0.0\n",
      "{'C': 33.9322177189533}\n"
     ]
    }
   ],
   "source": [
    "head_LR1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9804305283757339 0.0 0.019569471624266144 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksi01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "head_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
